#!/usr/bin/env python3
# -*- coding: utf-8 -*-


"""
Transpile (roughly means convert) a JSON AST file to Python source code.
"""


from operator import itemgetter
import argparse
import copy
import glob
import itertools
import json
import logging
import os
import pprint
import sys
import textwrap

from calculateur_impots.core import mapcat
from calculateur_impots.transpiler import to_dependencies_visitors, to_python_source_visitors
from calculateur_impots.transpiler.base import sanitized_variable_name
from calculateur_impots.transpiler.dependencies_helpers import get_ordered_formulas_names


# Globals


args = None
script_name = os.path.splitext(os.path.basename(__file__))[0]
log = logging.getLogger(script_name)

script_dir_path = os.path.dirname(os.path.abspath(__file__))
generated_dir_path = os.path.abspath(os.path.join(script_dir_path, '..', 'generated'))


# Python helpers

list_ = list  # To use in ipdb since "list" is reserved to display the current source code.


# Source code helper functions


def get_formula_source(formula_source_by_name, formula_name):
    return formula_source_by_name.get(
        formula_name,
        '{} = 0'.format(formula_name),
        )


def lines_to_python_source(sequence):
    return ''.join(itertools.chain.from_iterable(zip(sequence, itertools.repeat('\n'))))


def read_ast_json_file(json_file_name):
    json_file_path = os.path.join(args.json_dir, json_file_name)
    with open(json_file_path) as json_file:
        json_str = json_file.read()
    nodes = json.loads(json_str)
    assert isinstance(nodes, list)
    return nodes


def write_source_file(file_name, source):
    header = """\
# -*- coding: utf-8 -*-
# flake8: noqa
# WARNING: This file is automatically generated by a script. No not modify it by hand!
"""
    file_path = os.path.join(generated_dir_path, file_name)
    with open(file_path, 'w') as output_file:
        output_file.write(lines_to_python_source((header, source)))
    log.info('Output file "{}" written with success'.format(file_path))


# Load files functions


def iter_json_file_names(*pathnames):
    for json_file_path in sorted(mapcat(
                lambda pathname: glob.iglob(os.path.join(args.json_dir, pathname)),
                pathnames,
                )):
        json_file_name = os.path.basename(json_file_path)
        if args.json is None or args.json == json_file_name:
            file_name_head = os.path.splitext(json_file_name)[0]
            yield json_file_name


def load_regles_file(json_file_name):
    log.info('Loading "{}"...'.format(json_file_name))
    regles_nodes = read_ast_json_file(json_file_name)
    batch_application_regles_nodes = list(filter(
        lambda node: 'batch' in node['applications'],
        regles_nodes,
        ))
    # dependencies = list(map(to_dependencies_visitors.visit_node, batch_application_regles_nodes))
    formula_name_and_source_list = mapcat(to_python_source_visitors.visit_node, batch_application_regles_nodes)
    return formula_name_and_source_list


def load_tgvH_file():
    json_file_name = 'tgvH.json'
    log.info('Loading "{}"...'.format(json_file_name))
    nodes = read_ast_json_file(json_file_name)
    variable_definition_by_name = {
        sanitized_variable_name(node['name']): node
        for node in nodes
        if node['type'].startswith('variable_')
        }
    return variable_definition_by_name


# def load_verifs_file(json_file_name):
#     log.info('Loading "{}"...'.format(json_file_name))
#     verifs_nodes = read_ast_json_file(json_file_name)


# Main


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-d', '--debug', action='store_true', default=False, help='Display debug messages')
    parser.add_argument('--json', help='Parse only this JSON file and exit')
    parser.add_argument('-v', '--verbose', action='store_true', default=False, help='Increase output verbosity')
    parser.add_argument('json_dir', help='Directory containing the JSON AST files')
    global args
    args = parser.parse_args()
    logging.basicConfig(
        level=logging.DEBUG if args.debug else (logging.INFO if args.verbose else logging.WARNING),
        stream=sys.stdout,
        )

    if not os.path.isdir(generated_dir_path):
        os.mkdir(generated_dir_path)

    if args.json is not None:
        json_file_path = os.path.join(args.json_dir, args.json)
        if not os.path.exists(json_file_path):
            parser.error('JSON file "{}" does not exist.'.format(json_file_path))

    # Transpile variables definitions (before regles)
    variable_definition_by_name = load_tgvH_file()
    write_source_file(
        file_name='variables_definitions.py',
        source='variable_definition_by_name = {}\n'.format(pprint.pformat(variable_definition_by_name, width=120)),
        )

    # Load regles
    formula_source_by_name = dict(mapcat(
        load_regles_file,
        iter_json_file_names('chap-*.json', 'res-ser*.json'),
        ))
    # import ipdb; ipdb.set_trace()
    # formula_source_by_name = dict(mapcat())

    # Load verifs
    # for json_file_name in iter_json_file_names('coc*.json', 'coi*.json'):
        # load_verifs_file(json_file_name)

    # Output transpiled sources to Python file.
    variables_const = list(filter(lambda v: v['type'] == 'variable_const', variable_definition_by_name.values()))
    ordered_formulas_names = get_ordered_formulas_names(formula_dependencies_by_name)
    write_source_file(
        file_name='constants.py',
        source=lines_to_python_source(map(
            to_python_source_visitors.visit_node,
            sorted(variables_const, key=itemgetter('name')),
            )),
        )
    write_source_file(
        file_name='formulas.py',
        source=lines_to_python_source(itertools.chain(
            (
                'from ..core import *',
                'from .constants import *',
                '\n',
                ),
            map(get_formula_source, ordered_formulas_names),
            )),
        )

    return 0


if __name__ == '__main__':
    sys.exit(main())
